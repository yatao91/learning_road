## sparkSQL针对array及object(struct)类型的打平操作

#### 概述

业务上, 需要使用`sparkSQL`装在`elasticsearch`中的业务数据, 但业务索引中包含`object`类型及多值字段的情况, 在加载为`dataframe`后, 对应字段类型被推断(infer)为`array/object`类型. 

首次加载后的`schema`如下所示:

```json
root
 |-- agency: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |    |    |-- stock_code: string (nullable = true)
 |    |    |-- stock_company: struct (nullable = true)
 |    |    |    |-- city: string (nullable = true)
 |    |    |    |-- name: string (nullable = true)
 |    |    |    |-- province: string (nullable = true)
 |-- bid_company: struct (nullable = true)
 |    |-- city: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- province: string (nullable = true)
 |    |-- stock_code: string (nullable = true)
 |    |-- stock_company: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |-- bid_money: float (nullable = true)
 |-- owner: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |    |    |-- stock_code: string (nullable = true)
 |    |    |-- stock_company: struct (nullable = true)
 |    |    |    |-- city: string (nullable = true)
 |    |    |    |-- name: string (nullable = true)
 |    |    |    |-- province: string (nullable = true)
 |-- project_city: string (nullable = true)
 |-- project_province: string (nullable = true)
 |-- publish_time: timestamp (nullable = true)
```

因需要使用`sparkSQL`对`dataframe`进行临时表创建等工作. 此种嵌套结构的`dataframe`不适合, 需要进行打平操作.

#### 1.使用explode(爆炸)处理array类型字段

针对`array`类型的字段, 需要使用`sparkSQL`提供的函数`explode`进行处理. 处理后, 一条文档将根据array中的元素个数被分为与元素个数相同的条数.

`explode`函数文档如下:

```python
Returns a new row for each element in the given array or map.

>>> from pyspark.sql import Row
>>> eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={"hardware": "b"})])
>>> eDF.select(explode(eDF.intlist).alias("anInt")).collect()
[Row(anInt=1), Row(anInt=2), Row(anInt=3)]
>>> eDF.select(explode(eDF.mapfield).alias("key", "value")).show()
+---+-----+
|key|value|
+---+-----+
|  a|    b|
+---+-----+
```

比如一条下面的数据:

```json
{"name": "john", "favorite": ["hardware", "b", "c"]}
```

通过使用`explode`后, 将会变成以下数据:

```json
{"name": "john", "favorite": "hardware"}
{"name": "john", "favorite": "b"}
{"name": "john", "favorite": "c"}
```

具体使用`pyspark`编程如下:

```python
first_explode_df = df \
    .select(df['publish_time'],
            df['bid_company'],
            df['project_province'],
            df['project_city'],
            df['owner'],
            explode(df['agency']).alias("agency"))  # 对agency字段使用explode分裂数据字段

first_explode_df.printSchema()
```

分裂的`schema`如下:

```json
root
 |-- publish_time: timestamp (nullable = true)
 |-- bid_company: struct (nullable = true)
 |    |-- city: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- province: string (nullable = true)
 |    |-- stock_code: string (nullable = true)
 |    |-- stock_company: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |-- project_province: string (nullable = true)
 |-- project_city: string (nullable = true)
 |-- owner: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |    |    |-- stock_code: string (nullable = true)
 |    |    |-- stock_company: struct (nullable = true)
 |    |    |    |-- city: string (nullable = true)
 |    |    |    |-- name: string (nullable = true)
 |    |    |    |-- province: string (nullable = true)
 |-- agency: struct (nullable = true)  // explode后转变为struct类型
 |    |-- city: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- province: string (nullable = true)
 |    |-- stock_code: string (nullable = true)
 |    |-- stock_company: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
```

当一条数据中有多个字段类型为`array`时, 不能一次性在多个字段上分别使用`explode`, 需要逐步进行分裂.

```python
# 第一阶段:对agency字段进行explode操作
first_explode_df = df \
    .select(df['publish_time'],
            df['bid_company'],
            df['project_province'],
            df['project_city'],
            df['owner'],
            explode(df['agency']).alias("agency"))

first_explode_df.printSchema()

# 第二阶段:对owner字段进行explode操作
second_explode_df = first_explode_df \
    .select(first_explode_df['publish_time'],
            first_explode_df['bid_company'],
            first_explode_df['project_province'],
            first_explode_df['project_city'],
            first_explode_df["agency"],
            explode(first_explode_df['owner']).alias("owner"))

second_explode_df.printSchema()
```

多`array`类型字段均执行`explode`后的`schema`如下所示:

```json
root
 |-- publish_time: timestamp (nullable = true)
 |-- bid_company: struct (nullable = true)
 |    |-- city: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- province: string (nullable = true)
 |    |-- stock_code: string (nullable = true)
 |    |-- stock_company: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |-- project_province: string (nullable = true)
 |-- project_city: string (nullable = true)
 |-- agency: struct (nullable = true)  // array-->struct
 |    |-- city: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- province: string (nullable = true)
 |    |-- stock_code: string (nullable = true)
 |    |-- stock_company: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
 |-- owner: struct (nullable = true)  // array-->struct
 |    |-- city: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- province: string (nullable = true)
 |    |-- stock_code: string (nullable = true)
 |    |-- stock_company: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- name: string (nullable = true)
 |    |    |-- province: string (nullable = true)
```

#### 2.针对嵌套字段(struct)进行打平操作

由第一步可以看到, 已经将`array`类型的字段处理为`struct`类型. 但仍然没有将`dataframe`打平. 

那么我们当前需要将`struct`类型的字段进行打平操作.

采用的方式为: 对`array`处理的`dataframe`进行`select`操作, 将所需字段取出来, 并根据需要进行赋别名操作. `pyspark`下代码如下:

```python
final_df = second_explode_df\
    .select(second_explode_df['publish_time'],
            second_explode_df['bid_company.name'].alias('bid_company'),
            second_explode_df['bid_company.province'].alias('bid_company_province'),
            second_explode_df['bid_company.city'].alias('bid_company_city'),
            second_explode_df['project_province'],
            second_explode_df['project_city'],
            second_explode_df['agency.name'].alias("agency"),
            second_explode_df['agency.province'].alias("agency_province"),
            second_explode_df['agency.city'].alias("agency_city"),
            second_explode_df['owner.name'].alias("owner"),
            second_explode_df['owner.province'].alias("owner_province"),
            second_explode_df['owner.city'].alias("owner_city"))
final_df.printSchema()
```

打平后得到的`dataframe`的`schema`如下所示:

```json
root
 |-- publish_time: timestamp (nullable = true)
 |-- bid_company: string (nullable = true)
 |-- bid_company_province: string (nullable = true)
 |-- bid_company_city: string (nullable = true)
 |-- project_province: string (nullable = true)
 |-- project_city: string (nullable = true)
 |-- agency: string (nullable = true)
 |-- agency_province: string (nullable = true)
 |-- agency_city: string (nullable = true)
 |-- owner: string (nullable = true)
 |-- owner_province: string (nullable = true)
 |-- owner_city: string (nullable = true)
```

#### 总结:

使用`explode`打平数组字段的原理是: 将数组中的元素拆分, 每个元素对应生成新的一行数据. 即当一条数据中存在一个`array`类型的字段, 对其进行打平操作时, 将会变成`array`元素数对应行数.如下所示:

```python
>>> from pyspark.sql import Row
>>> eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={"hardware": "b"})])
>>> eDF.select(explode(eDF.intlist).alias("anInt")).collect()
[Row(anInt=1), Row(anInt=2), Row(anInt=3)]
```

> 一行数据, 经过`explode`后, 变成了三行.

以上方案是使用的`sparkSQL`加载数据, 并在`dataframe`上进行的操作.

其实还有另外一种方案: 可以将数据加载为`RDD`, 然后使用`RDD`进行`map`操作, 来打平, 然后再转成`dataframe`进行后续操作. 

#### 注意

当在某个数据集`dataframe`上对某个`array`字段使用`explode`进行打平操作时, 如果`dataframe`中有部分数据此字段不存在, 将会导致生成的新的`dataframe`中这些数据的丢失. 其实这是使用`explode`时的正常表现--只会处理存在此`array`字段的数据. 如果想要避免这种情况, 可以使用`explode_outer`函数来进行打平操作.

`explode_outer`函数的具体使用见下一节.

#### 引用

> [【Spark】使用DataFrame读取复杂JSON中的嵌套数组](http://www.lubinsu.com/index.php/archives/493)
>
> [HOW TO HANDLE NESTED DATA/ARRAY OF STRUCTURES OR MULTIPLE EXPLODES IN SPARK/SCALA AND PYSPARK:](https://hadoopist.wordpress.com/2016/05/16/how-to-handle-nested-dataarray-of-structures-or-multiple-explodes-in-sparkscala-and-pyspark/)

